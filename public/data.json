[
  {
    "username": "Fotis_Adamakis",
    "title": "RIP Styled-Components. Now What?",
    "banner": "https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BssOkI5X8n_uBhGcbHDhdA.png",
    "body" : "Styled-components are officially in maintenance mode. No new features or major updates should be expected. Only critical bug fixes and security patches will be addressed from now on. If your styling depends on them, you’re on a legacy track! Why Styled-Components Fell Out of Favor. Three big reasons: 1. React moved on. React is deprecating parts of its API (like the legacy context API) that styled-components depended on. No upgrade path, no workaround. The library is stuck. 2. The ecosystem evolved. CSS-in-JS isn’t the hot thing anymore. The ecosystem is leaning toward Tailwind, PostCSS, and traditional CSS modules. Less runtime overhead, better DX with modern tooling. 3. Maintainer burnout. The lead maintainer, Evan Jacobs, hasn’t been using styled-components in production for years. No active usage means no motivation to push it forward. So… What Now?If you’re starting a new project, styled-components shouldn’t even be on your radar. For existing codebases, start thinking about migration."
  },
  {
    "username": "Medium_Newsletter",
    "title": "A definition of “vibe coding,” or: how AI is turning everyone into a software developer",
    "banner": "https://miro.medium.com/v2/resize:fit:2000/format:webp/0*nOd4xby-JPQsQy-_",
    "body" : "In issue #282, we featured a story by product designer Ben Snyder, who used AI to build a rudimentary game in which you (an ostrich) must jump over a barrage of obstacles, and if you don’t you die. Snyder and his kids built the game with Replit and v0, two apps that let you “blink software into reality,” as Pete Sena describes it on Medium. You can ask either app to “build a game where you have to jump to avoid monsters,” and they’ll do so instantly.The term for this style of on-command software development is “vibe coding” — Andrej Karpathy, cofounder of OpenAI, coined it last month and it instantly caught on. The idea: Instead of developers writing literal lines of code, anyone can direct AI to build based on a prompt… and tweak from there. In Kaprathy’s words: “it’s not really coding — I just see stuff, say stuff, run stuff, and copy paste stuff, and it mostly works.” Vibe coding is a mindset more than a method. It’s about giving into AI’s potential — giving into the vibe of AI-driven development — rather than fighting it. Sena views vibe coding as simply the latest development in the Great Democratization Cycle of every technology. We saw this happen to photography (goodbye darkrooms, hello digital photos), publishing (goodbye printing press, hello blogging), even video and music production. Technology always cheapens the means of production, increasing productivity (the amount of photos taken, stories told, code written…) and making truly innovative work that much more valuable. In the world vibe coding is creating, expertise still matters, but it’s a different type of expertise. Now that the gap between ideas and execution has been reduced to basically zero, we’ll place even more of a premium on great ideas and elegant execution."
  },
  {
    "username": "NEXT_Network",
    "title": "How long and how deep will tech winter be?",
    "banner": "https://miro.medium.com/v2/resize:fit:1400/format:webp/1*40PnTHVsTXWeKh8xjSaswA.jpeg",
    "body" : "Tech winter is here. It could be a minor blip or a deep shock, taking years to recover. Where is the fuel for the next tech boom? In May 2022, Y Combinator warned its portfolio founders to “plan for the worst”. Cutting expenses and, if that wouldn’t suffice to reach profitability, raising capital was the name of the new game. The subject line read “Economic Downturn”. Clearly, the long honeymoon of venture-backed tech startups was over. Tech winter was coming, and now it’s here. But how long and how deep will it be? Looking back at recent tech history, we find two different models: the burst of the dot-com bubble in 2001. the Great Recession in 2008. The former was a deep shock, and it took years for the tech industry to recover. The latter was, in hindsight at least, a minor blip. But what it set in motion was a long period of cheap capital, fuelling the tech revolution for 15 years. The Great Recession and its aftermath, the financial crisis, led central banks to a policy of low, sometimes even negative interest rates. In addition, they absorbed a lot of treasury bonds. Governments could load up new debt without worrying about rising interest rates. Many companies and private individuals followed suit. Rising house prices were partly stoked by this cheap money. And the same is true for the meteoric rise of Big Tech stocks. A lot of the abundant money available went to the stock market and tech stocks in particular. As growth stocks, low interest rates gave them an advantage. That’s because markets are supposed to discount future earnings. Profits in the future are worth less than profits today. How much less is influenced by interest rates. The lower they are, the lower the discount rate. Profits in the future become more valuable. Thus, economic long-term thinking and sustainability get tailwinds. Low interest rates dampen the breathless short-termism of the capital markets. The long- and medium-term future is coming into view."
  },
  {
    "username": "Kristina Bogović",
    "title": "Can AI see beauty?",
    "banner": "https://miro.medium.com/v2/resize:fit:2000/format:webp/1*oyV-Ev0m-G0OmWlk45XL2Q.png",
    "body" : "Meta recently released a research paper proposing an AI model called Audiobox-Aesthetics. It’s designed to predict how people might rate the aesthetic quality of audio by assigning scores across four categories: production quality, production complexity, content enjoyment, and content usefulness. Each clip would be divided into ten-second chunks, normalized for loudness, and evaluated by a transformer-based system trained on listener ratings. Former Pandora analyst Jeffrey Anthony is skeptical that beauty can be quantified. Beauty, he argues, isn’t something you can extract from a waveform. It depends on context and sequence, not clean averages. “Aesthetic meaning,” he writes, “is not something that emerges from a statistical averaging of disjointed moments.” He concedes the model could be useful for optimizing platform recommendations, but stresses that it can’t understand why a song moves a person. AI-generated images raise a similar concern for writer and activist Cory Doctorow. He argues that true art isn’t defined by fidelity or polish, but rather the accumulation of unconscious choices, each one shaped by a particular hand and mind. Without that thread of human intent, AI-generated images might be technically impressive, but they don’t communicate. Doctorow sees a lack of human intent as a fatal flaw of AI. But in my experience, intention can still guide the process. During a deep Midjourney phase a few years ago, I started generating portraits of my novel’s characters, just to see them more clearly. I crafted highly specific prompts, adjusted the outputs, and iterated through hundreds of versions until I got what I wanted. It wasn’t about handing over creative control, but about using available technology to help actualize my vision. The images helped me describe the characters in sharper detail. It felt intuitive, not mechanical. Anthony and Doctorow argue that AI can imitate the look or sound of beauty, but it doesn’t understand what makes it matter. Meaning comes from perspective, they say. I would retort that AI might not create with perspective, but it can reflect ours. And using these tools doesn’t always mean surrendering meaning."
  }
]